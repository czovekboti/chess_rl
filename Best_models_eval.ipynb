{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/czovekboti/chess_rl/blob/sft%2Bgrpo/Final_models_eval\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOai9JD7vVxY"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "  https://colab.research.google.com/github/czovekboti/chess_rl/blob/sft%2Bgrpo/Model%20Evaluation.ipynb\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti-Ea7FAVeOg",
        "outputId": "fcc9455c-6110-4bf9-9e6a-7cf447eea2fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth\n",
            "  Downloading unsloth-2025.12.1-py3-none-any.whl.metadata (65 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-chess\n",
            "  Downloading python_chess-1.999-py3-none-any.whl.metadata (776 bytes)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Collecting unsloth_zoo>=2025.12.3 (from unsloth)\n",
            "  Downloading unsloth_zoo-2025.12.3-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (25.0)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.24.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-1.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth)\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.5.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (1.12.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.18.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.2)\n",
            "Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth)\n",
            "  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting chess<2,>=1 (from python-chess)\n",
            "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\n",
            "Collecting torchao>=0.13.0 (from unsloth_zoo>=2025.12.3->unsloth)\n",
            "  Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.12.3->unsloth)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.12.3->unsloth)\n",
            "  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting torch>=2.4.0 (from unsloth)\n",
            "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.10.2.21->torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.1.2->torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12==11.3.0.4->torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton>=3.0.0 (from unsloth)\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from unsloth)\n",
            "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (0.17.0)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\n",
            "Downloading unsloth-2025.12.1-py3-none-any.whl (359 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.7/359.7 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n",
            "Downloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.12.3-py3-none-any.whl (288 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.6/288.6 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m905.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m136.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m145.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-1.0.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m136.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: chess\n",
            "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=0ff0ee6f3e037348dcdc25118cd9c18043e998231068acfdca0ab804f3c52e20\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/1f/4e/8f4300f7dd554eb8de70ddfed96e94d3d030ace10c5b53d447\n",
            "Successfully built chess\n",
            "Installing collected packages: torchao, triton, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, colorama, chess, tyro, python-chess, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, datasets, xformers, torchvision, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth\n",
            "  Attempting uninstall: torchao\n",
            "    Found existing installation: torchao 0.10.0\n",
            "    Uninstalling torchao-0.10.0:\n",
            "      Successfully uninstalled torchao-0.10.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.0+cu126\n",
            "    Uninstalling torchvision-0.24.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.24.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.48.2 chess-1.11.2 colorama-0.4.6 cut_cross_entropy-25.1.1 datasets-4.3.0 msgspec-0.20.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 pyarrow-22.0.0 python-chess-1.999 torch-2.9.1 torchao-0.14.1 torchvision-0.24.1 triton-3.5.1 trl-0.24.0 tyro-1.0.0 unsloth-2025.12.1 unsloth_zoo-2025.12.3 xformers-0.0.33.post2\n",
            "Requirement already satisfied: python-chess in /usr/local/lib/python3.12/dist-packages (1.999)\n",
            "Requirement already satisfied: chess<2,>=1 in /usr/local/lib/python3.12/dist-packages (from python-chess) (1.11.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  polyglot xboard | scid\n",
            "The following NEW packages will be installed:\n",
            "  stockfish\n",
            "0 upgraded, 1 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 24.8 MB of archives.\n",
            "After this operation, 47.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 stockfish amd64 14.1-1 [24.8 MB]\n",
            "Fetched 24.8 MB in 1s (19.0 MB/s)\n",
            "Selecting previously unselected package stockfish.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../stockfish_14.1-1_amd64.deb ...\n",
            "Unpacking stockfish (14.1-1) ...\n",
            "Setting up stockfish (14.1-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "#@title Colab Extra Install { display-mode: \"form\" }\n",
        "#%%capture\n",
        "!pip install unsloth python-chess datasets matplotlib pandas tqdm python-dotenv colorama transformers\n",
        "!pip install python-chess\n",
        "!apt-get install stockfish"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "745jT_9DdcBA"
      },
      "source": [
        "# Add how many examples the script should eval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import chess\n",
        "import chess.engine\n",
        "import re\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from unsloth import FastLanguageModel\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import time\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a chess coach assistant. You will be given a board position in FEN format. Your job is to analyze the board and suggest the best legal move for the player whose turn it is.\n",
        "\n",
        "Please follow this exact format in your response:\n",
        "\n",
        "<reasoning>\n",
        "(Brief explanation of what you see on the board — piece activity, threats, and candidate moves)\n",
        "</reasoning>\n",
        "<answer>\n",
        "(best move written in correct SAN format, such as Nf3 or exd5)\n",
        "</answer>\n",
        "\n",
        "Do not invent illegal or impossible moves. The move must be legal in the given FEN position.\n",
        "Do not use UCI format like e2e4 — only SAN notation like e4, Nf3, or O-O.\n",
        "In case of taking a piece use the [file]x[target square] format\n",
        "### Example:\n",
        "FEN: rnbqkbnr/pppppppp/8/8/4P3/5N2/PPPP1PPP/RNBQKB1R b KQkq - 1 1\n",
        "\n",
        "<reasoning>\n",
        "White has just played e4 and developed the knight to f3. It's Black's turn. The e4 pawn is undefended. Capturing it with the pawn from d7 to d5 is a natural central counter.\n",
        "</reasoning>\n",
        "<answer>\n",
        "d5\n",
        "</answer>\n",
        "\n",
        "Now solve the following position:\n",
        "\"\"\"\n",
        "\n",
        "class ChessModelEvaluator:\n",
        "    def __init__(self, model_path, model_name, stockfish_path=\"/usr/games/stockfish\",\n",
        "                 max_seq_length=1024, lora_rank=32, num_generations=1,\n",
        "                 model=None, tokenizer=None):\n",
        "        \"\"\"\n",
        "        Initialize the evaluator with a model.\n",
        "\n",
        "        Args:\n",
        "            model_path: Path to the model (ignored if model and tokenizer provided)\n",
        "            model_name: Name for saving results (e.g., \"sft_model\", \"grpo_model\")\n",
        "            stockfish_path: Path to stockfish executable\n",
        "            max_seq_length: Maximum sequence length for model\n",
        "            lora_rank: LoRA rank for model loading\n",
        "            num_generations: Number of generations per position\n",
        "            model: Pre-loaded model (optional, avoids reloading)\n",
        "            tokenizer: Pre-loaded tokenizer (optional, avoids reloading)\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.num_generations = num_generations\n",
        "\n",
        "        # Load model if not provided\n",
        "        if model is not None and tokenizer is not None:\n",
        "            print(f\"Using pre-loaded model for: {model_name}\")\n",
        "            self.model = model\n",
        "            self.tokenizer = tokenizer\n",
        "        else:\n",
        "            print(f\"Loading model: {model_path}\")\n",
        "            self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "                model_name=model_path,\n",
        "                max_seq_length=max_seq_length,\n",
        "                load_in_4bit=False,\n",
        "                fast_inference=False,\n",
        "                max_lora_rank=lora_rank,\n",
        "                gpu_memory_utilization=0.8,\n",
        "                resize_model_vocab=151669,\n",
        "            )\n",
        "            FastLanguageModel.for_inference(self.model)\n",
        "\n",
        "        # Initialize chess engine\n",
        "        print(f\"Initializing Stockfish from: {stockfish_path}\")\n",
        "        self.engine = chess.engine.SimpleEngine.popen_uci(stockfish_path)\n",
        "\n",
        "    def extract_move_from_response(self, response):\n",
        "        \"\"\"Extract move from model response.\"\"\"\n",
        "        match = re.search(r'<answer>\\s*([^\\s<]+)\\s*</answer>', response, re.IGNORECASE)\n",
        "        if match:\n",
        "            return match.group(1).strip()\n",
        "        return None\n",
        "\n",
        "    def has_correct_format(self, response):\n",
        "        \"\"\"Check if response has correct format with reasoning and answer tags.\"\"\"\n",
        "        has_reasoning = bool(re.search(r'<reasoning>.*?</reasoning>', response, re.IGNORECASE | re.DOTALL))\n",
        "        has_answer = bool(re.search(r'<answer>.*?</answer>', response, re.IGNORECASE | re.DOTALL))\n",
        "        return has_reasoning and has_answer\n",
        "\n",
        "    def fen_color(self, fen):\n",
        "        \"\"\"Extract which color is to move from FEN.\"\"\"\n",
        "        parts = fen.split()\n",
        "        if len(parts) >= 2:\n",
        "            return \"White\" if parts[1] == 'w' else \"Black\"\n",
        "        return \"White\"  # Default\n",
        "\n",
        "    def get_game_phase(self, board):\n",
        "        \"\"\"Determine game phase based on material and move count.\"\"\"\n",
        "        move_count = board.fullmove_number\n",
        "        piece_count = len(board.piece_map())\n",
        "\n",
        "        if move_count <= 10 or piece_count >= 28:\n",
        "            return \"opening\"\n",
        "        elif piece_count <= 12 or move_count >= 40:\n",
        "            return \"endgame\"\n",
        "        else:\n",
        "            return \"middlegame\"\n",
        "\n",
        "    def count_material(self, board):\n",
        "        \"\"\"Count total material on board.\"\"\"\n",
        "        piece_values = {'P': 1, 'N': 3, 'B': 3, 'R': 5, 'Q': 9, 'K': 0}\n",
        "        total = 0\n",
        "        for piece in board.piece_map().values():\n",
        "            total += piece_values.get(piece.symbol().upper(), 0)\n",
        "        return total\n",
        "\n",
        "    def is_tactical(self, board):\n",
        "        \"\"\"Check if position is tactical (checks, captures available).\"\"\"\n",
        "        if board.is_check():\n",
        "            return True\n",
        "        # Check if there are any capture moves\n",
        "        for move in board.legal_moves:\n",
        "            if board.is_capture(move):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def get_position_type(self, best_eval, top_evals):\n",
        "        \"\"\"Classify position type based on evaluation.\"\"\"\n",
        "        if abs(best_eval) > 300:\n",
        "            return \"winning\" if best_eval > 0 else \"losing\"\n",
        "        elif abs(best_eval) < 50:\n",
        "            return \"equal\"\n",
        "        else:\n",
        "            return \"advantage\"\n",
        "\n",
        "    def classify_move_quality(self, cp_loss):\n",
        "        \"\"\"Classify move quality based on centipawn loss.\"\"\"\n",
        "        if cp_loss is None:\n",
        "            return \"illegal\"\n",
        "        elif cp_loss <= 10:\n",
        "            return \"excellent\"\n",
        "        elif cp_loss <= 50:\n",
        "            return \"good\"\n",
        "        elif cp_loss <= 100:\n",
        "            return \"inaccuracy\"\n",
        "        elif cp_loss <= 300:\n",
        "            return \"mistake\"\n",
        "        else:\n",
        "            return \"blunder\"\n",
        "\n",
        "    def generate_move(self, fen):\n",
        "        \"\"\"Generate a move for the given FEN position.\"\"\"\n",
        "        # Format prompt exactly as during training\n",
        "        messages = [\n",
        "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "            {'role': 'user', 'content': fen + \" You are with the following pieces: \" + self.fen_color(fen)}\n",
        "        ]\n",
        "\n",
        "        # Apply chat template\n",
        "        prompt = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        inputs = self.tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        outputs = self.model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=256,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "        )\n",
        "        inference_time = time.time() - start_time\n",
        "\n",
        "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        # Extract only the generated part (after the prompt)\n",
        "        response = response[len(prompt):].strip()\n",
        "\n",
        "        # Count tokens in response\n",
        "        response_tokens = len(self.tokenizer.encode(response))\n",
        "\n",
        "        return response, inference_time, response_tokens\n",
        "\n",
        "    def evaluate_position(self, fen, ground_truth_eval=None):\n",
        "        \"\"\"\n",
        "        Evaluate model's move for a given position.\n",
        "\n",
        "        Returns dict with evaluation metrics for this position.\n",
        "        \"\"\"\n",
        "        board = chess.Board(fen)\n",
        "        phase = self.get_game_phase(board)\n",
        "        material = self.count_material(board)\n",
        "        is_tactical = self.is_tactical(board)\n",
        "        move_number = board.fullmove_number\n",
        "\n",
        "        # Get top moves from Stockfish\n",
        "        info = self.engine.analyse(board, chess.engine.Limit(depth=20), multipv=5)\n",
        "\n",
        "        # Extract top moves and their evaluations\n",
        "        top_moves = []\n",
        "        top_evals = []\n",
        "        for i, analysis in enumerate(info if isinstance(info, list) else [info]):\n",
        "            move = analysis[\"pv\"][0]\n",
        "            score = analysis[\"score\"].relative\n",
        "            top_moves.append(board.san(move))\n",
        "            # Convert score to centipawns\n",
        "            if score.is_mate():\n",
        "                cp = 10000 if score.mate() > 0 else -10000\n",
        "            else:\n",
        "                cp = score.score()\n",
        "            top_evals.append(cp)\n",
        "\n",
        "        best_move = top_moves[0] if top_moves else None\n",
        "        best_eval = top_evals[0] if top_evals else 0\n",
        "        position_type = self.get_position_type(best_eval, top_evals)\n",
        "\n",
        "        # Check if position is sharp (multiple good moves with similar eval)\n",
        "        is_sharp = False\n",
        "        if len(top_evals) >= 3:\n",
        "            eval_spread = max(top_evals[:3]) - min(top_evals[:3])\n",
        "            is_sharp = eval_spread < 30  # If top 3 moves within 30 CP\n",
        "\n",
        "        results = []\n",
        "        all_moves = []  # For consistency checking\n",
        "\n",
        "        # Generate multiple moves if requested\n",
        "        for gen_idx in range(self.num_generations):\n",
        "            response, inference_time, response_tokens = self.generate_move(fen)\n",
        "            model_move = self.extract_move_from_response(response)\n",
        "            has_correct_format = self.has_correct_format(response)\n",
        "            all_moves.append(model_move)\n",
        "\n",
        "            # Evaluate the move\n",
        "            is_legal = False\n",
        "            is_best = False\n",
        "            is_top3 = False\n",
        "            is_top5 = False\n",
        "            centipawn_loss = None\n",
        "            move_eval = None\n",
        "            move_quality = \"illegal\"\n",
        "\n",
        "            # Check for draw to loss conversion\n",
        "            draw_to_loss = False\n",
        "            win_preserved = None\n",
        "\n",
        "            if model_move:\n",
        "                try:\n",
        "                    # Check if move is legal\n",
        "                    move_obj = board.parse_san(model_move)\n",
        "                    is_legal = True\n",
        "\n",
        "                    # Get evaluation after this move\n",
        "                    board.push(move_obj)\n",
        "                    result = self.engine.analyse(board, chess.engine.Limit(depth=20))\n",
        "                    score = result[\"score\"].relative\n",
        "\n",
        "                    # Convert to centipawns (from opponent's perspective, so negate)\n",
        "                    if score.is_mate():\n",
        "                        move_eval = -10000 if score.mate() > 0 else 10000\n",
        "                    else:\n",
        "                        move_eval = -score.score()\n",
        "\n",
        "                    board.pop()\n",
        "\n",
        "                    # Calculate centipawn loss\n",
        "                    centipawn_loss = best_eval - move_eval\n",
        "                    move_quality = self.classify_move_quality(centipawn_loss)\n",
        "\n",
        "                    # Check if it's in top moves\n",
        "                    is_best = (model_move == best_move)\n",
        "                    is_top3 = (model_move in top_moves[:3])\n",
        "                    is_top5 = (model_move in top_moves[:5])\n",
        "\n",
        "                    # Check draw to loss conversion\n",
        "                    if abs(best_eval) < 50:  # Position was roughly equal\n",
        "                        if move_eval < -150:  # Move leads to losing position\n",
        "                            draw_to_loss = True\n",
        "\n",
        "                    # Check win preservation\n",
        "                    if best_eval > 300:  # Position was winning\n",
        "                        win_preserved = move_eval > 200  # Still winning after move\n",
        "\n",
        "                except (chess.IllegalMoveError, chess.InvalidMoveError, chess.AmbiguousMoveError):\n",
        "                    pass\n",
        "\n",
        "            results.append({\n",
        "                'fen': fen,\n",
        "                'generation_idx': gen_idx,\n",
        "                'model_move': model_move,\n",
        "                'best_move': best_move,\n",
        "                'top_3_moves': ','.join(top_moves[:3]) if len(top_moves) >= 3 else ','.join(top_moves),\n",
        "                'top_5_moves': ','.join(top_moves[:5]) if len(top_moves) >= 5 else ','.join(top_moves),\n",
        "                'is_legal': is_legal,\n",
        "                'is_best': is_best,\n",
        "                'is_top3': is_top3,\n",
        "                'is_top5': is_top5,\n",
        "                'best_eval': best_eval,\n",
        "                'move_eval': move_eval,\n",
        "                'centipawn_loss': centipawn_loss,\n",
        "                'move_quality': move_quality,\n",
        "                'game_phase': phase,\n",
        "                'move_number': move_number,\n",
        "                'material_count': material,\n",
        "                'is_tactical': is_tactical,\n",
        "                'is_sharp': is_sharp,\n",
        "                'position_type': position_type,\n",
        "                'draw_to_loss': draw_to_loss,\n",
        "                'win_preserved': win_preserved,\n",
        "                'correct_format': has_correct_format,\n",
        "                'inference_time': inference_time,\n",
        "                'response_tokens': response_tokens,\n",
        "                'ground_truth_eval': ground_truth_eval,\n",
        "                'full_response': response\n",
        "            })\n",
        "\n",
        "        # Calculate consistency metrics (only if multiple generations)\n",
        "        if self.num_generations > 1:\n",
        "            legal_moves = [m for m in all_moves if m is not None]\n",
        "            if len(legal_moves) > 1:\n",
        "                most_common = max(set(legal_moves), key=legal_moves.count)\n",
        "                consistency_rate = legal_moves.count(most_common) / len(legal_moves)\n",
        "            else:\n",
        "                consistency_rate = 0.0\n",
        "\n",
        "            # Add consistency to all results for this position\n",
        "            for r in results:\n",
        "                r['move_consistency'] = consistency_rate\n",
        "\n",
        "        return results\n",
        "\n",
        "    def evaluate_dataset(self, dataset, num_samples=None, output_path=None):\n",
        "        \"\"\"\n",
        "        Evaluate model on a dataset of positions.\n",
        "\n",
        "        Args:\n",
        "            dataset: HuggingFace dataset with 'FEN' column\n",
        "            num_samples: Number of samples to evaluate (None = all)\n",
        "            output_path: Path to save CSV results\n",
        "        \"\"\"\n",
        "        if num_samples:\n",
        "            dataset = dataset.select(range(min(num_samples, len(dataset))))\n",
        "\n",
        "        all_results = []\n",
        "\n",
        "        print(f\"Evaluating {len(dataset)} positions...\")\n",
        "        for idx, example in enumerate(tqdm(dataset)):\n",
        "            fen = example['FEN']\n",
        "            ground_truth = example.get('Evaluation', None)\n",
        "\n",
        "            try:\n",
        "                position_results = self.evaluate_position(fen, ground_truth)\n",
        "                all_results.extend(position_results)\n",
        "            except Exception as e:\n",
        "                print(f\"Error on position {idx}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Create DataFrame\n",
        "        df = pd.DataFrame(all_results)\n",
        "\n",
        "        # Save to CSV\n",
        "        if output_path is None:\n",
        "            output_path = f\"{self.model_name}_results.csv\"\n",
        "\n",
        "        df.to_csv(output_path, index=False)\n",
        "        print(f\"Results saved to {output_path}\")\n",
        "\n",
        "        # Print summary statistics\n",
        "        self.print_summary(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def print_summary(self, df):\n",
        "        \"\"\"Print summary statistics.\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Summary for {self.model_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Total positions: {len(df[df['generation_idx'] == 0])}\")\n",
        "        print(f\"Total generations: {len(df)}\")\n",
        "\n",
        "        print(f\"\\n=== CORE METRICS ===\")\n",
        "        print(f\"Legal move rate: {df['is_legal'].mean()*100:.2f}%\")\n",
        "        print(f\"Best move rate: {df['is_best'].mean()*100:.2f}%\")\n",
        "        print(f\"Top-3 move rate: {df['is_top3'].mean()*100:.2f}%\")\n",
        "        print(f\"Top-5 move rate: {df['is_top5'].mean()*100:.2f}%\")\n",
        "        print(f\"Format compliance: {df['correct_format'].mean()*100:.2f}%\")\n",
        "\n",
        "        legal_moves = df[df['is_legal']]\n",
        "        if len(legal_moves) > 0:\n",
        "            print(f\"\\n=== CENTIPAWN METRICS ===\")\n",
        "            print(f\"Avg centipawn loss: {legal_moves['centipawn_loss'].mean():.2f}\")\n",
        "            print(f\"Median centipawn loss: {legal_moves['centipawn_loss'].median():.2f}\")\n",
        "            print(f\"Std dev centipawn loss: {legal_moves['centipawn_loss'].std():.2f}\")\n",
        "\n",
        "            print(f\"\\n=== MOVE QUALITY BREAKDOWN ===\")\n",
        "            for quality in ['excellent', 'good', 'inaccuracy', 'mistake', 'blunder']:\n",
        "                count = (legal_moves['move_quality'] == quality).sum()\n",
        "                pct = count / len(legal_moves) * 100\n",
        "                print(f\"{quality.capitalize()}: {pct:.2f}% ({count}/{len(legal_moves)})\")\n",
        "\n",
        "        print(f\"\\n=== POSITION TYPE PERFORMANCE ===\")\n",
        "        for pos_type in ['winning', 'advantage', 'equal', 'losing']:\n",
        "            type_df = df[df['position_type'] == pos_type]\n",
        "            if len(type_df) > 0:\n",
        "                print(f\"{pos_type.capitalize()}: Legal={type_df['is_legal'].mean()*100:.1f}%, Best={type_df['is_best'].mean()*100:.1f}%\")\n",
        "\n",
        "        # Draw to loss conversion\n",
        "        draw_positions = df[df['position_type'] == 'equal']\n",
        "        if len(draw_positions) > 0:\n",
        "            draw_to_loss_rate = draw_positions['draw_to_loss'].sum() / len(draw_positions) * 100\n",
        "            print(f\"\\nDraw to loss conversion rate: {draw_to_loss_rate:.2f}%\")\n",
        "\n",
        "        # Win preservation\n",
        "        win_positions = df[df['position_type'] == 'winning']\n",
        "        if len(win_positions) > 0:\n",
        "            win_preserved = win_positions['win_preserved'].sum() / len(win_positions) * 100\n",
        "            print(f\"Win preservation rate: {win_preserved:.2f}%\")\n",
        "\n",
        "        print(f\"\\n=== GAME PHASE PERFORMANCE ===\")\n",
        "        for phase in ['opening', 'middlegame', 'endgame']:\n",
        "            phase_df = df[df['game_phase'] == phase]\n",
        "            if len(phase_df) > 0:\n",
        "                print(f\"{phase.capitalize()}: Legal={phase_df['is_legal'].mean()*100:.1f}%, Best={phase_df['is_best'].mean()*100:.1f}%\", end=\"\")\n",
        "                legal_phase = phase_df[phase_df['is_legal']]\n",
        "                if len(legal_phase) > 0:\n",
        "                    print(f\", CP Loss={legal_phase['centipawn_loss'].mean():.1f}\")\n",
        "                else:\n",
        "                    print()\n",
        "\n",
        "        print(f\"\\n=== TACTICAL VS POSITIONAL ===\")\n",
        "        tactical_df = df[df['is_tactical']]\n",
        "        positional_df = df[~df['is_tactical']]\n",
        "        if len(tactical_df) > 0:\n",
        "            print(f\"Tactical: Legal={tactical_df['is_legal'].mean()*100:.1f}%, Best={tactical_df['is_best'].mean()*100:.1f}%\")\n",
        "        if len(positional_df) > 0:\n",
        "            print(f\"Positional: Legal={positional_df['is_legal'].mean()*100:.1f}%, Best={positional_df['is_best'].mean()*100:.1f}%\")\n",
        "\n",
        "        print(f\"\\n=== SHARP VS QUIET ===\")\n",
        "        sharp_df = df[df['is_sharp']]\n",
        "        quiet_df = df[~df['is_sharp']]\n",
        "        if len(sharp_df) > 0:\n",
        "            print(f\"Sharp: Legal={sharp_df['is_legal'].mean()*100:.1f}%, Best={sharp_df['is_best'].mean()*100:.1f}%\")\n",
        "        if len(quiet_df) > 0:\n",
        "            print(f\"Quiet: Legal={quiet_df['is_legal'].mean()*100:.1f}%, Best={quiet_df['is_best'].mean()*100:.1f}%\")\n",
        "\n",
        "        print(f\"\\n=== EFFICIENCY METRICS ===\")\n",
        "        print(f\"Avg inference time: {df['inference_time'].mean():.3f}s\")\n",
        "        print(f\"Avg response tokens: {df['response_tokens'].mean():.1f}\")\n",
        "\n",
        "        if self.num_generations > 1 and 'move_consistency' in df.columns:\n",
        "            print(f\"\\n=== CONSISTENCY ===\")\n",
        "            print(f\"Avg move consistency: {df['move_consistency'].mean()*100:.1f}%\")\n",
        "\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "    def cleanup(self):\n",
        "        \"\"\"Cleanup resources.\"\"\"\n",
        "        self.engine.quit()\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Configuration\n",
        "    MODEL_PATH = \"czovekboti/stf_model\"  # Change this for different models\n",
        "    MODEL_NAME = \"sft_model\"  # Change this for naming output files\n",
        "    NUM_SAMPLES = 3  # Number of positions to evaluate (None for all)\n",
        "    NUM_GENERATIONS = 2  # Number of generations per position\n",
        "\n",
        "    # Load dataset\n",
        "    print(\"Loading dataset...\")\n",
        "    dataset = load_dataset(\"czovekboti/chessdata\", split=\"train\")\n",
        "\n",
        "    # Option 1: Load model once and reuse it\n",
        "    print(\"Loading model (will be reused)...\")\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=MODEL_PATH,\n",
        "        max_seq_length=1024,\n",
        "        load_in_4bit=False,\n",
        "        fast_inference=False,\n",
        "        max_lora_rank=32,\n",
        "        gpu_memory_utilization=0.8,\n",
        "        resize_model_vocab=151669,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model)\n",
        "\n",
        "    # Initialize evaluator with pre-loaded model\n",
        "    evaluator = ChessModelEvaluator(\n",
        "        model_path=MODEL_PATH,  # Not used when model is provided\n",
        "        model_name=MODEL_NAME,\n",
        "        stockfish_path=\"/usr/games/stockfish\",  # Adjust if needed\n",
        "        num_generations=NUM_GENERATIONS,\n",
        "        model=model,  # Pass pre-loaded model\n",
        "        tokenizer=tokenizer  # Pass pre-loaded tokenizer\n",
        "    )\n",
        "\n",
        "    # Run evaluation\n",
        "    results_df = evaluator.evaluate_dataset(\n",
        "        dataset=dataset,\n",
        "        num_samples=NUM_SAMPLES,\n",
        "        output_path=f\"{MODEL_NAME}_results.csv\"\n",
        "    )\n",
        "\n",
        "    # Cleanup\n",
        "    evaluator.cleanup()\n",
        "\n",
        "    print(\"Evaluation complete!\")\n",
        "\n",
        "    # Option 2: If you want to evaluate multiple model variants without reloading base model\n",
        "    # You can create multiple evaluators with the same model and tokenizer:\n",
        "    # evaluator2 = ChessModelEvaluator(\n",
        "    #     model_path=None,\n",
        "    #     model_name=\"same_model_variant2\",\n",
        "    #     num_generations=3,\n",
        "    #     model=model,\n",
        "    #     tokenizer=tokenizer\n",
        "    # )"
      ],
      "metadata": {
        "id": "jP9PA6bmQnmM",
        "outputId": "11184433-b96b-4290-db60-a64a8659ef94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "439fc85115e94eb6a17fc7e7a85712f8",
            "662de5dba508463b80f89dcce67d0128",
            "b6974b786f284e65bbe9ac64c08a1b9b",
            "66e773c76d794f479cd180ee51cf6801",
            "c45a1a594e534c889ceefb11c12596d6",
            "60b3757e1aa747e1b80778ce23611dd8",
            "afdc1bf24c704ee5b7cf777f3f71a3fa",
            "9374e0c7cb844882bd9f3f6e64cf2bdc",
            "c137df3d63cf4141b5dca18dc85993b4",
            "3e89199761e7400b9a3a3f6a1f2d736c",
            "b12bdd9215c247668e38a2a9c432eb3b"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "Loading dataset...\n",
            "Loading model (will be reused)...\n",
            "==((====))==  Unsloth 2025.12.1: Fast Qwen3 patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "439fc85115e94eb6a17fc7e7a85712f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.12.1 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pre-loaded model for: sft_model\n",
            "Initializing Stockfish from: /usr/games/stockfish\n",
            "Evaluating 3 positions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [01:19<00:00, 26.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to sft_model_results.csv\n",
            "\n",
            "============================================================\n",
            "Summary for sft_model\n",
            "============================================================\n",
            "Total positions: 3\n",
            "Total generations: 6\n",
            "\n",
            "=== CORE METRICS ===\n",
            "Legal move rate: 33.33%\n",
            "Best move rate: 16.67%\n",
            "Top-3 move rate: 16.67%\n",
            "Top-5 move rate: 16.67%\n",
            "Format compliance: 0.00%\n",
            "\n",
            "=== CENTIPAWN METRICS ===\n",
            "Avg centipawn loss: 20.50\n",
            "Median centipawn loss: 20.50\n",
            "Std dev centipawn loss: 23.33\n",
            "\n",
            "=== MOVE QUALITY BREAKDOWN ===\n",
            "Excellent: 50.00% (1/2)\n",
            "Good: 50.00% (1/2)\n",
            "Inaccuracy: 0.00% (0/2)\n",
            "Mistake: 0.00% (0/2)\n",
            "Blunder: 0.00% (0/2)\n",
            "\n",
            "=== POSITION TYPE PERFORMANCE ===\n",
            "Advantage: Legal=0.0%, Best=0.0%\n",
            "Equal: Legal=50.0%, Best=25.0%\n",
            "\n",
            "Draw to loss conversion rate: 0.00%\n",
            "\n",
            "=== GAME PHASE PERFORMANCE ===\n",
            "Opening: Legal=33.3%, Best=16.7%, CP Loss=20.5\n",
            "\n",
            "=== TACTICAL VS POSITIONAL ===\n",
            "Positional: Legal=33.3%, Best=16.7%\n",
            "\n",
            "=== SHARP VS QUIET ===\n",
            "Sharp: Legal=50.0%, Best=0.0%\n",
            "Quiet: Legal=25.0%, Best=25.0%\n",
            "\n",
            "=== EFFICIENCY METRICS ===\n",
            "Avg inference time: 6.579s\n",
            "Avg response tokens: 64.3\n",
            "\n",
            "=== CONSISTENCY ===\n",
            "Avg move consistency: 50.0%\n",
            "============================================================\n",
            "\n",
            "Evaluation complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8om7vB_0SLXh",
        "outputId": "86d1b5ba-c72d-42b9-a74a-138715efc4b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1 models: sft_model\n",
            "\n",
            "================================================================================\n",
            "GENERATING COMPREHENSIVE COMPARATIVE ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "COMPREHENSIVE MODEL COMPARISON\n",
            "====================================================================================================\n",
            "    Model  Positions  Legal (%)  Best (%)  Top-3 (%)  Top-5 (%)  Format (%)  Avg CP Loss  Med CP Loss  Std CP Loss  Excellent (%)  Blunder (%)  Mistake (%)  Inaccuracy (%)  Draw→Loss (%)  Avg Time (s)  Avg Tokens\n",
            "sft_model          3      33.33     16.67      16.67      16.67        0.00        20.50        20.50        23.33          50.00         0.00         0.00            0.00           0.00          6.58       64.33\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Generating visualizations...\n",
            "Saved: chess_analysis_results/01_core_metrics.png\n",
            "Saved: chess_analysis_results/02_move_quality.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2264365787.py:269: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  bp = axes[1, 1].boxplot(data_for_box, labels=labels_for_box, patch_artist=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: chess_analysis_results/03_centipawn_analysis.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2264365787.py:353: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  grouped = df[df['is_legal']].groupby('move_range')['is_best'].mean() * 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: chess_analysis_results/04_phase_analysis.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2264365787.py:431: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
            "  axes[1, 0].set_ylim([0, max(data) * 1.2 if data else 100])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: chess_analysis_results/05_position_type.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2264365787.py:540: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  grouped = df[df['is_legal']].groupby('material_range')['is_best'].mean() * 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: chess_analysis_results/06_tactical_positional.png\n",
            "Saved: chess_analysis_results/07_efficiency.png\n",
            "Saved: chess_analysis_results/08_radar_comparison.png\n",
            "Saved: chess_analysis_results/09_agreement_matrix.png\n",
            "Saved: chess_analysis_results/10_elo_estimation.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2264365787.py:851: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "  axes[1, 0].legend()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: chess_analysis_results/11_scatter_relationships.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2264365787.py:921: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "  axes[0, 1].legend()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: chess_analysis_results/12_time_series_trends.png\n",
            "\n",
            "================================================================================\n",
            "✓ ANALYSIS COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "All results saved to 'chess_analysis_results/' directory\n",
            "\n",
            "Generated files:\n",
            "  📊 summary_comparison.csv - Detailed metrics table\n",
            "  📈 01_core_metrics.png - Core performance metrics\n",
            "  📈 02_move_quality.png - Move quality breakdown\n",
            "  📈 03_centipawn_analysis.png - Centipawn loss analysis\n",
            "  📈 04_phase_analysis.png - Game phase performance\n",
            "  📈 05_position_type.png - Position type analysis\n",
            "  📈 06_tactical_positional.png - Tactical vs positional\n",
            "  📈 07_efficiency.png - Speed and efficiency metrics\n",
            "  📈 08_radar_comparison.png - Multi-dimensional radar chart\n",
            "  📈 09_agreement_matrix.png - Model agreement heatmap\n",
            "  📈 10_elo_estimation.png - Estimated playing strength\n",
            "  📈 11_scatter_relationships.png - Scatter plots of relationships\n",
            "  📈 12_time_series_trends.png - Performance trends across game\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import glob\n",
        "from scipy import stats\n",
        "\n",
        "class ChessModelComparison:\n",
        "    def __init__(self, csv_files):\n",
        "        \"\"\"\n",
        "        Initialize comparison with multiple model result CSVs.\n",
        "\n",
        "        Args:\n",
        "            csv_files: List of paths to CSV files or a pattern (e.g., \"*_results.csv\")\n",
        "        \"\"\"\n",
        "        if isinstance(csv_files, str):\n",
        "            csv_files = glob.glob(csv_files)\n",
        "\n",
        "        self.dataframes = {}\n",
        "        self.model_names = []\n",
        "\n",
        "        for csv_file in csv_files:\n",
        "            model_name = Path(csv_file).stem.replace('_results', '')\n",
        "            df = pd.read_csv(csv_file)\n",
        "            self.dataframes[model_name] = df\n",
        "            self.model_names.append(model_name)\n",
        "\n",
        "        print(f\"Loaded {len(self.model_names)} models: {', '.join(self.model_names)}\")\n",
        "\n",
        "        # Set style\n",
        "        sns.set_style(\"whitegrid\")\n",
        "        plt.rcParams['figure.figsize'] = (12, 6)\n",
        "        self.colors = sns.color_palette(\"husl\", len(self.model_names))\n",
        "\n",
        "    def create_summary_table(self):\n",
        "        \"\"\"Create a comprehensive summary table comparing all models.\"\"\"\n",
        "        summary_data = []\n",
        "\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            legal_df = df[df['is_legal']]\n",
        "\n",
        "            # Basic metrics\n",
        "            row = {\n",
        "                'Model': model_name,\n",
        "                'Positions': len(df[df['generation_idx'] == 0]),\n",
        "                'Legal (%)': df['is_legal'].mean() * 100,\n",
        "                'Best (%)': df['is_best'].mean() * 100,\n",
        "                'Top-3 (%)': df['is_top3'].mean() * 100,\n",
        "                'Top-5 (%)': df['is_top5'].mean() * 100,\n",
        "                'Format (%)': df['correct_format'].mean() * 100,\n",
        "            }\n",
        "\n",
        "            if len(legal_df) > 0:\n",
        "                row['Avg CP Loss'] = legal_df['centipawn_loss'].mean()\n",
        "                row['Med CP Loss'] = legal_df['centipawn_loss'].median()\n",
        "                row['Std CP Loss'] = legal_df['centipawn_loss'].std()\n",
        "\n",
        "                # Move quality\n",
        "                row['Excellent (%)'] = (legal_df['move_quality'] == 'excellent').mean() * 100\n",
        "                row['Blunder (%)'] = (legal_df['move_quality'] == 'blunder').mean() * 100\n",
        "                row['Mistake (%)'] = (legal_df['move_quality'] == 'mistake').mean() * 100\n",
        "                row['Inaccuracy (%)'] = (legal_df['move_quality'] == 'inaccuracy').mean() * 100\n",
        "\n",
        "            # Draw to loss\n",
        "            draw_df = df[df['position_type'] == 'equal']\n",
        "            if len(draw_df) > 0:\n",
        "                row['Draw→Loss (%)'] = draw_df['draw_to_loss'].sum() / len(draw_df) * 100\n",
        "\n",
        "            # Win preservation\n",
        "            win_df = df[df['position_type'] == 'winning']\n",
        "            if len(win_df) > 0:\n",
        "                row['Win Kept (%)'] = win_df['win_preserved'].sum() / len(win_df) * 100\n",
        "\n",
        "            # Efficiency\n",
        "            row['Avg Time (s)'] = df['inference_time'].mean()\n",
        "            row['Avg Tokens'] = df['response_tokens'].mean()\n",
        "\n",
        "            summary_data.append(row)\n",
        "\n",
        "        summary_df = pd.DataFrame(summary_data)\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
        "        print(\"=\"*100)\n",
        "        print(summary_df.to_string(index=False, float_format='%.2f'))\n",
        "        print(\"=\"*100 + \"\\n\")\n",
        "\n",
        "        return summary_df\n",
        "\n",
        "    def plot_core_metrics(self, save_path='core_metrics.png'):\n",
        "        \"\"\"Plot core performance metrics.\"\"\"\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "        metrics = [\n",
        "            ('Legal (%)', 'is_legal', 100),\n",
        "            ('Best (%)', 'is_best', 100),\n",
        "            ('Top-3 (%)', 'is_top3', 100),\n",
        "            ('Top-5 (%)', 'is_top5', 100),\n",
        "            ('Format (%)', 'correct_format', 100),\n",
        "            ('Avg CP Loss', 'centipawn_loss', 1)\n",
        "        ]\n",
        "\n",
        "        for idx, (label, col, multiplier) in enumerate(metrics):\n",
        "            ax = axes[idx // 3, idx % 3]\n",
        "            data = []\n",
        "            labels = []\n",
        "\n",
        "            for model_name in self.model_names:\n",
        "                df = self.dataframes[model_name]\n",
        "                if col == 'centipawn_loss':\n",
        "                    legal_df = df[df['is_legal']]\n",
        "                    value = legal_df[col].mean() if len(legal_df) > 0 else 0\n",
        "                else:\n",
        "                    value = df[col].mean() * multiplier\n",
        "\n",
        "                data.append(value)\n",
        "                labels.append(model_name)\n",
        "\n",
        "            bars = ax.bar(labels, data, color=self.colors, alpha=0.8)\n",
        "            ax.set_ylabel(label)\n",
        "            ax.set_title(label, fontsize=12, fontweight='bold')\n",
        "\n",
        "            if col != 'centipawn_loss':\n",
        "                ax.set_ylim([0, 100])\n",
        "\n",
        "            # Add value labels\n",
        "            for i, (bar, v) in enumerate(zip(bars, data)):\n",
        "                height = bar.get_height()\n",
        "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                       f'{v:.1f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Saved: {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def plot_move_quality_breakdown(self, save_path='move_quality_breakdown.png'):\n",
        "        \"\"\"Plot detailed move quality breakdown.\"\"\"\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "        qualities = ['excellent', 'good', 'inaccuracy', 'mistake', 'blunder']\n",
        "        quality_colors = ['#2ecc71', '#3498db', '#f39c12', '#e67e22', '#e74c3c']\n",
        "\n",
        "        # Stacked bar chart\n",
        "        x = np.arange(len(self.model_names))\n",
        "        width = 0.6\n",
        "        bottom = np.zeros(len(self.model_names))\n",
        "\n",
        "        for quality, color in zip(qualities, quality_colors):\n",
        "            values = []\n",
        "            for model_name in self.model_names:\n",
        "                df = self.dataframes[model_name]\n",
        "                legal_df = df[df['is_legal']]\n",
        "                if len(legal_df) > 0:\n",
        "                    pct = (legal_df['move_quality'] == quality).mean() * 100\n",
        "                    values.append(pct)\n",
        "                else:\n",
        "                    values.append(0)\n",
        "\n",
        "            axes[0].bar(x, values, width, bottom=bottom, label=quality.capitalize(),\n",
        "                       color=color, alpha=0.8)\n",
        "            bottom += values\n",
        "\n",
        "        axes[0].set_ylabel('Percentage (%)')\n",
        "        axes[0].set_title('Move Quality Distribution (Stacked)', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_xticks(x)\n",
        "        axes[0].set_xticklabels(self.model_names)\n",
        "        axes[0].legend(loc='upper right')\n",
        "        axes[0].set_ylim([0, 100])\n",
        "\n",
        "        # Grouped bar for key categories\n",
        "        key_categories = ['Excellent', 'Blunder', 'Mistake']\n",
        "        x = np.arange(len(key_categories))\n",
        "        width = 0.8 / len(self.model_names)\n",
        "\n",
        "        for i, model_name in enumerate(self.model_names):\n",
        "            df = self.dataframes[model_name]\n",
        "            legal_df = df[df['is_legal']]\n",
        "\n",
        "            if len(legal_df) > 0:\n",
        "                excellent = (legal_df['move_quality'] == 'excellent').mean() * 100\n",
        "                blunder = (legal_df['move_quality'] == 'blunder').mean() * 100\n",
        "                mistake = (legal_df['move_quality'] == 'mistake').mean() * 100\n",
        "                values = [excellent, blunder, mistake]\n",
        "            else:\n",
        "                values = [0, 0, 0]\n",
        "\n",
        "            offset = (i - len(self.model_names)/2 + 0.5) * width\n",
        "            axes[1].bar(x + offset, values, width, label=model_name,\n",
        "                       color=self.colors[i], alpha=0.8)\n",
        "\n",
        "        axes[1].set_ylabel('Percentage (%)')\n",
        "        axes[1].set_title('Key Move Categories', fontsize=12, fontweight='bold')\n",
        "        axes[1].set_xticks(x)\n",
        "        axes[1].set_xticklabels(key_categories)\n",
        "        axes[1].legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Saved: {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def plot_centipawn_analysis(self, save_path='centipawn_analysis.png'):\n",
        "        \"\"\"Comprehensive centipawn loss analysis.\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        # 1. CP Loss distribution\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            legal_df = df[df['is_legal']]\n",
        "            if len(legal_df) > 0:\n",
        "                cp_loss = legal_df['centipawn_loss'].clip(0, 500)\n",
        "                axes[0, 0].hist(cp_loss, bins=50, alpha=0.5, label=model_name, density=True)\n",
        "\n",
        "        axes[0, 0].set_xlabel('Centipawn Loss')\n",
        "        axes[0, 0].set_ylabel('Density')\n",
        "        axes[0, 0].set_title('CP Loss Distribution', fontsize=12, fontweight='bold')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].axvline(x=0, color='red', linestyle='--', alpha=0.3)\n",
        "\n",
        "        # 2. Cumulative CP Loss\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            legal_df = df[df['is_legal']]\n",
        "            if len(legal_df) > 0:\n",
        "                sorted_cp = np.sort(legal_df['centipawn_loss'])\n",
        "                cumulative = np.arange(1, len(sorted_cp) + 1) / len(sorted_cp) * 100\n",
        "                axes[0, 1].plot(sorted_cp, cumulative, label=model_name, linewidth=2)\n",
        "\n",
        "        axes[0, 1].set_xlabel('Centipawn Loss')\n",
        "        axes[0, 1].set_ylabel('Cumulative Percentage (%)')\n",
        "        axes[0, 1].set_title('Cumulative CP Loss', fontsize=12, fontweight='bold')\n",
        "        axes[0, 1].set_xlim([0, 300])\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # 3. CP Loss ranges\n",
        "        bins = [0, 50, 100, 200, 500, float('inf')]\n",
        "        labels = ['0-50', '50-100', '100-200', '200-500', '500+']\n",
        "\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            legal_df = df[df['is_legal']]\n",
        "            if len(legal_df) > 0:\n",
        "                binned = pd.cut(legal_df['centipawn_loss'], bins=bins, labels=labels)\n",
        "                counts = binned.value_counts().sort_index()\n",
        "                percentages = counts / len(legal_df) * 100\n",
        "                axes[1, 0].plot(labels, percentages, marker='o', label=model_name,\n",
        "                              linewidth=2, markersize=8)\n",
        "\n",
        "        axes[1, 0].set_xlabel('CP Loss Range')\n",
        "        axes[1, 0].set_ylabel('Percentage of Moves (%)')\n",
        "        axes[1, 0].set_title('Move Distribution by CP Loss Range', fontweight='bold')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 4. Box plot comparison\n",
        "        data_for_box = []\n",
        "        labels_for_box = []\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            legal_df = df[df['is_legal']]\n",
        "            if len(legal_df) > 0:\n",
        "                cp_clipped = legal_df['centipawn_loss'].clip(0, 500)\n",
        "                data_for_box.append(cp_clipped)\n",
        "                labels_for_box.append(model_name)\n",
        "\n",
        "        bp = axes[1, 1].boxplot(data_for_box, labels=labels_for_box, patch_artist=True)\n",
        "        for patch, color in zip(bp['boxes'], self.colors):\n",
        "            patch.set_facecolor(color)\n",
        "            patch.set_alpha(0.6)\n",
        "\n",
        "        axes[1, 1].set_ylabel('Centipawn Loss')\n",
        "        axes[1, 1].set_title('CP Loss Distribution (Box Plot)', fontweight='bold')\n",
        "        axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Saved: {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def plot_phase_analysis(self, save_path='phase_analysis.png'):\n",
        "        \"\"\"Analyze performance across game phases.\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        phases = ['opening', 'middlegame', 'endgame']\n",
        "        x = np.arange(len(phases))\n",
        "        width = 0.8 / len(self.model_names)\n",
        "\n",
        "        # Legal rate by phase\n",
        "        for i, model_name in enumerate(self.model_names):\n",
        "            df = self.dataframes[model_name]\n",
        "            values = []\n",
        "            for phase in phases:\n",
        "                phase_df = df[df['game_phase'] == phase]\n",
        "                values.append(phase_df['is_legal'].mean() * 100 if len(phase_df) > 0 else 0)\n",
        "\n",
        "            offset = (i - len(self.model_names)/2 + 0.5) * width\n",
        "            axes[0, 0].bar(x + offset, values, width, label=model_name,\n",
        "                          color=self.colors[i], alpha=0.8)\n",
        "\n",
        "        axes[0, 0].set_ylabel('Legal Rate (%)')\n",
        "        axes[0, 0].set_title('Legal Move Rate by Phase', fontweight='bold')\n",
        "        axes[0, 0].set_xticks(x)\n",
        "        axes[0, 0].set_xticklabels([p.capitalize() for p in phases])\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].set_ylim([0, 100])\n",
        "\n",
        "        # Best move rate by phase\n",
        "        for i, model_name in enumerate(self.model_names):\n",
        "            df = self.dataframes[model_name]\n",
        "            values = []\n",
        "            for phase in phases:\n",
        "                phase_df = df[df['game_phase'] == phase]\n",
        "                values.append(phase_df['is_best'].mean() * 100 if len(phase_df) > 0 else 0)\n",
        "\n",
        "            offset = (i - len(self.model_names)/2 + 0.5) * width\n",
        "            axes[0, 1].bar(x + offset, values, width, label=model_name,\n",
        "                          color=self.colors[i], alpha=0.8)\n",
        "\n",
        "        axes[0, 1].set_ylabel('Best Move Rate (%)')\n",
        "        axes[0, 1].set_title('Best Move Rate by Phase', fontweight='bold')\n",
        "        axes[0, 1].set_xticks(x)\n",
        "        axes[0, 1].set_xticklabels([p.capitalize() for p in phases])\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].set_ylim([0, 100])\n",
        "\n",
        "        # CP Loss by phase\n",
        "        for i, model_name in enumerate(self.model_names):\n",
        "            df = self.dataframes[model_name]\n",
        "            values = []\n",
        "            for phase in phases:\n",
        "                phase_df = df[(df['game_phase'] == phase) & (df['is_legal'])]\n",
        "                values.append(phase_df['centipawn_loss'].mean() if len(phase_df) > 0 else 0)\n",
        "\n",
        "            offset = (i - len(self.model_names)/2 + 0.5) * width\n",
        "            axes[1, 0].bar(x + offset, values, width, label=model_name,\n",
        "                          color=self.colors[i], alpha=0.8)\n",
        "\n",
        "        axes[1, 0].set_ylabel('Average CP Loss')\n",
        "        axes[1, 0].set_title('CP Loss by Phase', fontweight='bold')\n",
        "        axes[1, 0].set_xticks(x)\n",
        "        axes[1, 0].set_xticklabels([p.capitalize() for p in phases])\n",
        "        axes[1, 0].legend()\n",
        "\n",
        "        # Performance by move number\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            # Group by move number ranges\n",
        "            df['move_range'] = pd.cut(df['move_number'], bins=[0, 10, 20, 30, 40, 100],\n",
        "                                     labels=['1-10', '11-20', '21-30', '31-40', '40+'])\n",
        "            grouped = df[df['is_legal']].groupby('move_range')['is_best'].mean() * 100\n",
        "            axes[1, 1].plot(range(len(grouped)), grouped.values, marker='o',\n",
        "                          label=model_name, linewidth=2, markersize=8)\n",
        "\n",
        "        axes[1, 1].set_xlabel('Move Number Range')\n",
        "        axes[1, 1].set_ylabel('Best Move Rate (%)')\n",
        "        axes[1, 1].set_title('Performance by Move Number', fontweight='bold')\n",
        "        axes[1, 1].set_xticks(range(5))\n",
        "        axes[1, 1].set_xticklabels(['1-10', '11-20', '21-30', '31-40', '40+'])\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Saved: {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def plot_position_type_analysis(self, save_path='position_type_analysis.png'):\n",
        "        \"\"\"Analyze performance by position type.\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        pos_types = ['winning', 'advantage', 'equal', 'losing']\n",
        "        x = np.arange(len(pos_types))\n",
        "        width = 0.8 / len(self.model_names)\n",
        "\n",
        "        # Legal rate by position type\n",
        "        for i, model_name in enumerate(self.model_names):\n",
        "            df = self.dataframes[model_name]\n",
        "            values = []\n",
        "            for pos_type in pos_types:\n",
        "                type_df = df[df['position_type'] == pos_type]\n",
        "                values.append(type_df['is_legal'].mean() * 100 if len(type_df) > 0 else 0)\n",
        "\n",
        "            offset = (i - len(self.model_names)/2 + 0.5) * width\n",
        "            axes[0, 0].bar(x + offset, values, width, label=model_name,\n",
        "                          color=self.colors[i], alpha=0.8)\n",
        "\n",
        "        axes[0, 0].set_ylabel('Legal Rate (%)')\n",
        "        axes[0, 0].set_title('Legal Rate by Position Type', fontweight='bold')\n",
        "        axes[0, 0].set_xticks(x)\n",
        "        axes[0, 0].set_xticklabels([p.capitalize() for p in pos_types], rotation=15)\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].set_ylim([0, 110])\n",
        "\n",
        "        # Best move rate\n",
        "        for i, model_name in enumerate(self.model_names):\n",
        "            df = self.dataframes[model_name]\n",
        "            values = []\n",
        "            for pos_type in pos_types:\n",
        "                type_df = df[df['position_type'] == pos_type]\n",
        "                values.append(type_df['is_best'].mean() * 100 if len(type_df) > 0 else 0)\n",
        "\n",
        "            offset = (i - len(self.model_names)/2 + 0.5) * width\n",
        "            axes[0, 1].bar(x + offset, values, width, label=model_name,\n",
        "                          color=self.colors[i], alpha=0.8)\n",
        "\n",
        "        axes[0, 1].set_ylabel('Best Move Rate (%)')\n",
        "        axes[0, 1].set_title('Best Move Rate by Position Type', fontweight='bold')\n",
        "        axes[0, 1].set_xticks(x)\n",
        "        axes[0, 1].set_xticklabels([p.capitalize() for p in pos_types], rotation=15)\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].set_ylim([0, 110])\n",
        "\n",
        "        # Draw to loss conversion\n",
        "        data = []\n",
        "        labels = []\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            draw_df = df[df['position_type'] == 'equal']\n",
        "            if len(draw_df) > 0:\n",
        "                rate = draw_df['draw_to_loss'].sum() / len(draw_df) * 100\n",
        "                data.append(rate)\n",
        "                labels.append(model_name)\n",
        "\n",
        "        if data:\n",
        "            axes[1, 0].bar(labels, data, color=self.colors[:len(labels)], alpha=0.8)\n",
        "            axes[1, 0].set_ylabel('Draw to Loss Rate (%)')\n",
        "            axes[1, 0].set_title('Draw to Loss Conversion Rate', fontweight='bold')\n",
        "            axes[1, 0].set_ylim([0, max(data) * 1.2 if data else 100])\n",
        "            for i, v in enumerate(data):\n",
        "                axes[1, 0].text(i, v + max(data)*0.02, f'{v:.1f}%', ha='center', fontsize=10)\n",
        "        else:\n",
        "            axes[1, 0].text(0.5, 0.5, 'No equal positions in sample',\n",
        "                          ha='center', va='center', transform=axes[1, 0].transAxes,\n",
        "                          fontsize=12, style='italic', color='gray')\n",
        "            axes[1, 0].set_title('Draw to Loss Conversion Rate', fontweight='bold')\n",
        "\n",
        "        # Win preservation\n",
        "        data = []\n",
        "        labels = []\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            win_df = df[df['position_type'] == 'winning']\n",
        "            if len(win_df) > 0:\n",
        "                rate = win_df['win_preserved'].sum() / len(win_df) * 100\n",
        "                data.append(rate)\n",
        "                labels.append(model_name)\n",
        "\n",
        "        if data:\n",
        "            axes[1, 1].bar(labels, data, color=self.colors[:len(labels)], alpha=0.8)\n",
        "            axes[1, 1].set_ylabel('Win Preservation Rate (%)')\n",
        "            axes[1, 1].set_title('Win Preservation Rate', fontweight='bold')\n",
        "            axes[1, 1].set_ylim([0, 110])\n",
        "            for i, v in enumerate(data):\n",
        "                axes[1, 1].text(i, v + 2, f'{v:.1f}%', ha='center', fontsize=10)\n",
        "        else:\n",
        "            axes[1, 1].text(0.5, 0.5, 'No winning positions in sample',\n",
        "                          ha='center', va='center', transform=axes[1, 1].transAxes,\n",
        "                          fontsize=12, style='italic', color='gray')\n",
        "            axes[1, 1].set_title('Win Preservation Rate', fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Saved: {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def plot_tactical_positional(self, save_path='tactical_positional.png'):\n",
        "        \"\"\"Compare tactical vs positional performance.\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "\n",
        "        categories = ['Tactical', 'Positional']\n",
        "        x = np.arange(len(categories))\n",
        "        width = 0.8 / len(self.model_names)\n",
        "\n",
        "        # Legal rate\n",
        "        for i, model_name in enumerate(self.model_names):\n",
        "            df = self.dataframes[model_name]\n",
        "            tactical = df[df['is_tactical']]['is_legal'].mean() * 100\n",
        "            positional = df[~df['is_tactical']]['is_legal'].mean() * 100\n",
        "            values = [tactical, positional]\n",
        "\n",
        "            offset = (i - len(self.model_names)/2 + 0.5) * width\n",
        "            axes[0, 0].bar(x + offset, values, width, label=model_name,\n",
        "                          color=self.colors[i], alpha=0.8)\n",
        "\n",
        "        axes[0, 0].set_ylabel('Legal Rate (%)')\n",
        "        axes[0, 0].set_title('Legal Rate: Tactical vs Positional', fontweight='bold')\n",
        "        axes[0, 0].set_xticks(x)\n",
        "        axes[0, 0].set_xticklabels(categories)\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].set_ylim([0, 100])\n",
        "\n",
        "        # Best move rate\n",
        "        for i, model_name in enumerate(self.model_names):\n",
        "            df = self.dataframes[model_name]\n",
        "            tactical = df[df['is_tactical']]['is_best'].mean() * 100\n",
        "            positional = df[~df['is_tactical']]['is_best'].mean() * 100\n",
        "            values = [tactical, positional]\n",
        "\n",
        "            offset = (i - len(self.model_names)/2 + 0.5) * width\n",
        "            axes[0, 1].bar(x + offset, values, width, label=model_name,\n",
        "                          color=self.colors[i], alpha=0.8)\n",
        "\n",
        "        axes[0, 1].set_ylabel('Best Move Rate (%)')\n",
        "        axes[0, 1].set_title('Best Move: Tactical vs Positional', fontweight='bold')\n",
        "        axes[0, 1].set_xticks(x)\n",
        "        axes[0, 1].set_xticklabels(categories)\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].set_ylim([0, 100])\n",
        "\n",
        "        # Sharp vs Quiet positions\n",
        "        categories = ['Sharp', 'Quiet']\n",
        "        x = np.arange(len(categories))\n",
        "\n",
        "        for i, model_name in enumerate(self.model_names):\n",
        "            df = self.dataframes[model_name]\n",
        "            sharp = df[df['is_sharp']]['is_best'].mean() * 100\n",
        "            quiet = df[~df['is_sharp']]['is_best'].mean() * 100\n",
        "            values = [sharp, quiet]\n",
        "\n",
        "            offset = (i - len(self.model_names)/2 + 0.5) * width\n",
        "            axes[1, 0].bar(x + offset, values, width, label=model_name,\n",
        "                          color=self.colors[i], alpha=0.8)\n",
        "\n",
        "        axes[1, 0].set_ylabel('Best Move Rate (%)')\n",
        "        axes[1, 0].set_title('Best Move: Sharp vs Quiet Positions', fontweight='bold')\n",
        "        axes[1, 0].set_xticks(x)\n",
        "        axes[1, 0].set_xticklabels(categories)\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].set_ylim([0, 100])\n",
        "\n",
        "        # Performance by material count\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            df['material_range'] = pd.cut(df['material_count'],\n",
        "                                         bins=[0, 20, 40, 60, 80, 100],\n",
        "                                         labels=['0-20', '20-40', '40-60', '60-80', '80+'])\n",
        "            grouped = df[df['is_legal']].groupby('material_range')['is_best'].mean() * 100\n",
        "            axes[1, 1].plot(range(len(grouped)), grouped.values, marker='o',\n",
        "                          label=model_name, linewidth=2, markersize=8)\n",
        "\n",
        "        axes[1, 1].set_xlabel('Material Count')\n",
        "        axes[1, 1].set_ylabel('Best Move Rate (%)')\n",
        "        axes[1, 1].set_title('Performance by Material Count', fontweight='bold')\n",
        "        axes[1, 1].set_xticks(range(5))\n",
        "        axes[1, 1].set_xticklabels(['0-20', '20-40', '40-60', '60-80', '80+'])\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Saved: {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def plot_efficiency_metrics(self, save_path='efficiency_metrics.png'):\n",
        "        \"\"\"Plot efficiency and consistency metrics.\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "\n",
        "        # Inference time\n",
        "        data = []\n",
        "        labels = []\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            data.append(df['inference_time'].mean())\n",
        "            labels.append(model_name)\n",
        "\n",
        "        axes[0, 0].bar(labels, data, color=self.colors, alpha=0.8)\n",
        "        axes[0, 0].set_ylabel('Time (seconds)')\n",
        "        axes[0, 0].set_title('Average Inference Time', fontweight='bold')\n",
        "        for i, v in enumerate(data):\n",
        "            axes[0, 0].text(i, v + max(data)*0.02, f'{v:.3f}s', ha='center', fontsize=10)\n",
        "\n",
        "        # Response tokens\n",
        "        data = []\n",
        "        labels = []\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            data.append(df['response_tokens'].mean())\n",
        "            labels.append(model_name)\n",
        "\n",
        "        axes[0, 1].bar(labels, data, color=self.colors, alpha=0.8)\n",
        "        axes[0, 1].set_ylabel('Token Count')\n",
        "        axes[0, 1].set_title('Average Response Length (tokens)', fontweight='bold')\n",
        "        for i, v in enumerate(data):\n",
        "            axes[0, 1].text(i, v + max(data)*0.02, f'{v:.1f}', ha='center', fontsize=10)\n",
        "\n",
        "        # Tokens per second\n",
        "        data = []\n",
        "        labels = []\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            tps = df['response_tokens'].mean() / df['inference_time'].mean()\n",
        "            data.append(tps)\n",
        "            labels.append(model_name)\n",
        "\n",
        "        axes[1, 0].bar(labels, data, color=self.colors, alpha=0.8)\n",
        "        axes[1, 0].set_ylabel('Tokens/Second')\n",
        "        axes[1, 0].set_title('Generation Speed', fontweight='bold')\n",
        "        for i, v in enumerate(data):\n",
        "            axes[1, 0].text(i, v + max(data)*0.02, f'{v:.1f}', ha='center', fontsize=10)\n",
        "\n",
        "        # Move consistency (if available)\n",
        "        if 'move_consistency' in self.dataframes[self.model_names[0]].columns:\n",
        "            data = []\n",
        "            labels = []\n",
        "            for model_name in self.model_names:\n",
        "                df = self.dataframes[model_name]\n",
        "                if df['move_consistency'].notna().any():\n",
        "                    data.append(df['move_consistency'].mean() * 100)\n",
        "                    labels.append(model_name)\n",
        "\n",
        "            if data:\n",
        "                axes[1, 1].bar(labels, data, color=self.colors[:len(labels)], alpha=0.8)\n",
        "                axes[1, 1].set_ylabel('Consistency (%)')\n",
        "                axes[1, 1].set_title('Move Consistency (Multi-generation)', fontweight='bold')\n",
        "                axes[1, 1].set_ylim([0, 100])\n",
        "                for i, v in enumerate(data):\n",
        "                    axes[1, 1].text(i, v + 2, f'{v:.1f}%', ha='center', fontsize=10)\n",
        "            else:\n",
        "                axes[1, 1].text(0.5, 0.5, 'No multi-generation data',\n",
        "                              ha='center', va='center', transform=axes[1, 1].transAxes,\n",
        "                              fontsize=12)\n",
        "                axes[1, 1].set_xticks([])\n",
        "                axes[1, 1].set_yticks([])\n",
        "        else:\n",
        "            axes[1, 1].text(0.5, 0.5, 'No consistency data available',\n",
        "                          ha='center', va='center', transform=axes[1, 1].transAxes,\n",
        "                          fontsize=12)\n",
        "            axes[1, 1].set_xticks([])\n",
        "            axes[1, 1].set_yticks([])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Saved: {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def plot_radar_comparison(self, save_path='radar_comparison.png'):\n",
        "        \"\"\"Create radar chart for multi-dimensional comparison.\"\"\"\n",
        "        from math import pi\n",
        "\n",
        "        categories = ['Legal\\nRate', 'Best\\nMove', 'Top-3', 'Low CP\\nLoss',\n",
        "                     'Win\\nPreserve', 'Format']\n",
        "        N = len(categories)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "        angles = [n / float(N) * 2 * pi for n in range(N)]\n",
        "        angles += angles[:1]\n",
        "\n",
        "        for i, model_name in enumerate(self.model_names):\n",
        "            df = self.dataframes[model_name]\n",
        "            legal_df = df[df['is_legal']]\n",
        "            win_df = df[df['position_type'] == 'winning']\n",
        "\n",
        "            values = [\n",
        "                df['is_legal'].mean() * 100,\n",
        "                df['is_best'].mean() * 100,\n",
        "                df['is_top3'].mean() * 100,\n",
        "                100 - (legal_df['centipawn_loss'].mean() / 5) if len(legal_df) > 0 else 0,  # Normalized\n",
        "                win_df['win_preserved'].mean() * 100 if len(win_df) > 0 else 0,\n",
        "                df['correct_format'].mean() * 100\n",
        "            ]\n",
        "            values += values[:1]\n",
        "\n",
        "            ax.plot(angles, values, 'o-', linewidth=2, label=model_name,\n",
        "                   color=self.colors[i])\n",
        "            ax.fill(angles, values, alpha=0.15, color=self.colors[i])\n",
        "\n",
        "        ax.set_xticks(angles[:-1])\n",
        "        ax.set_xticklabels(categories, size=10)\n",
        "        ax.set_ylim(0, 100)\n",
        "        ax.set_title('Multi-Dimensional Performance Comparison',\n",
        "                    size=14, fontweight='bold', pad=20)\n",
        "        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "        ax.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Saved: {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def plot_agreement_matrix(self, save_path='agreement_matrix.png'):\n",
        "        \"\"\"Create agreement matrix showing how often models agree.\"\"\"\n",
        "        n_models = len(self.model_names)\n",
        "        agreement_matrix = np.zeros((n_models, n_models))\n",
        "\n",
        "        # Get all positions from first model\n",
        "        first_df = self.dataframes[self.model_names[0]]\n",
        "        positions = first_df[first_df['generation_idx'] == 0]['fen'].unique()\n",
        "\n",
        "        for i, model1 in enumerate(self.model_names):\n",
        "            for j, model2 in enumerate(self.model_names):\n",
        "                if i == j:\n",
        "                    agreement_matrix[i, j] = 100\n",
        "                    continue\n",
        "\n",
        "                df1 = self.dataframes[model1]\n",
        "                df2 = self.dataframes[model2]\n",
        "\n",
        "                agreements = 0\n",
        "                total = 0\n",
        "\n",
        "                for fen in positions:\n",
        "                    move1 = df1[(df1['fen'] == fen) & (df1['generation_idx'] == 0)]['model_move'].values\n",
        "                    move2 = df2[(df2['fen'] == fen) & (df2['generation_idx'] == 0)]['model_move'].values\n",
        "\n",
        "                    if len(move1) > 0 and len(move2) > 0:\n",
        "                        if move1[0] == move2[0] and move1[0] is not None:\n",
        "                            agreements += 1\n",
        "                        total += 1\n",
        "\n",
        "                agreement_matrix[i, j] = (agreements / total * 100) if total > 0 else 0\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "        im = ax.imshow(agreement_matrix, cmap='YlOrRd', aspect='auto')\n",
        "\n",
        "        ax.set_xticks(np.arange(n_models))\n",
        "        ax.set_yticks(np.arange(n_models))\n",
        "        ax.set_xticklabels(self.model_names)\n",
        "        ax.set_yticklabels(self.model_names)\n",
        "\n",
        "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "        # Add text annotations\n",
        "        for i in range(n_models):\n",
        "            for j in range(n_models):\n",
        "                text = ax.text(j, i, f'{agreement_matrix[i, j]:.1f}%',\n",
        "                             ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
        "\n",
        "        ax.set_title('Model Agreement Matrix\\n(% of positions where models choose same move)',\n",
        "                    fontsize=12, fontweight='bold', pad=15)\n",
        "        fig.colorbar(im, ax=ax, label='Agreement Rate (%)')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Saved: {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def plot_elo_estimation(self, save_path='elo_estimation.png'):\n",
        "        \"\"\"Estimate and compare ELO ratings based on move quality.\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "        elo_estimates = []\n",
        "        model_labels = []\n",
        "\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            legal_df = df[df['is_legal']]\n",
        "\n",
        "            if len(legal_df) == 0:\n",
        "                continue\n",
        "\n",
        "            # Simple ELO estimation based on accuracy and CP loss\n",
        "            # This is a rough heuristic\n",
        "            best_move_rate = df['is_best'].mean()\n",
        "            top3_rate = df['is_top3'].mean()\n",
        "            avg_cp_loss = legal_df['centipawn_loss'].mean()\n",
        "\n",
        "            # Rough formula (not scientifically rigorous)\n",
        "            base_elo = 1500\n",
        "            accuracy_bonus = (best_move_rate * 800 + top3_rate * 400)\n",
        "            cp_penalty = min(avg_cp_loss * 2, 500)\n",
        "\n",
        "            estimated_elo = base_elo + accuracy_bonus - cp_penalty\n",
        "\n",
        "            elo_estimates.append(estimated_elo)\n",
        "            model_labels.append(model_name)\n",
        "\n",
        "        bars = ax.barh(model_labels, elo_estimates, color=self.colors, alpha=0.8)\n",
        "        ax.set_xlabel('Estimated ELO Rating', fontsize=12)\n",
        "        ax.set_title('Estimated Playing Strength (ELO)\\n(Rough approximation based on move quality)',\n",
        "                    fontsize=12, fontweight='bold')\n",
        "        ax.axvline(x=1500, color='red', linestyle='--', alpha=0.3, label='Base (1500)')\n",
        "        ax.legend()\n",
        "\n",
        "        for i, (bar, elo) in enumerate(zip(bars, elo_estimates)):\n",
        "            width = bar.get_width()\n",
        "            ax.text(width + 20, bar.get_y() + bar.get_height()/2,\n",
        "                   f'{elo:.0f}', ha='left', va='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Saved: {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def plot_scatter_relationships(self, save_path='scatter_relationships.png'):\n",
        "        \"\"\"Create scatter plots showing relationships between variables.\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        # 1. CP Loss vs Best Eval (position difficulty)\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            legal_df = df[df['is_legal'] & df['best_eval'].notna()]\n",
        "            if len(legal_df) > 0:\n",
        "                # Sample if too many points\n",
        "                if len(legal_df) > 500:\n",
        "                    legal_df = legal_df.sample(500, random_state=42)\n",
        "                axes[0, 0].scatter(legal_df['best_eval'], legal_df['centipawn_loss'],\n",
        "                                 alpha=0.4, s=30, label=model_name)\n",
        "\n",
        "        axes[0, 0].set_xlabel('Position Evaluation (centipawns)')\n",
        "        axes[0, 0].set_ylabel('Centipawn Loss')\n",
        "        axes[0, 0].set_title('CP Loss vs Position Evaluation', fontweight='bold')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        axes[0, 0].set_xlim([-500, 500])\n",
        "        axes[0, 0].set_ylim([0, 300])\n",
        "\n",
        "        # 2. Move Number vs Best Move Rate\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            # Group by move number\n",
        "            move_groups = df.groupby('move_number').agg({\n",
        "                'is_best': 'mean',\n",
        "                'fen': 'count'\n",
        "            }).reset_index()\n",
        "            # Filter groups with at least 3 positions\n",
        "            move_groups = move_groups[move_groups['fen'] >= 3]\n",
        "            if len(move_groups) > 0:\n",
        "                axes[0, 1].scatter(move_groups['move_number'],\n",
        "                                 move_groups['is_best'] * 100,\n",
        "                                 alpha=0.6, s=50, label=model_name)\n",
        "\n",
        "        axes[0, 1].set_xlabel('Move Number')\n",
        "        axes[0, 1].set_ylabel('Best Move Rate (%)')\n",
        "        axes[0, 1].set_title('Performance vs Move Number', fontweight='bold')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "        axes[0, 1].set_ylim([0, 100])\n",
        "\n",
        "        # 3. Material Count vs CP Loss\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            legal_df = df[df['is_legal']]\n",
        "            # Group by material count\n",
        "            material_groups = legal_df.groupby('material_count').agg({\n",
        "                'centipawn_loss': 'mean',\n",
        "                'fen': 'count'\n",
        "            }).reset_index()\n",
        "            material_groups = material_groups[material_groups['fen'] >= 3]\n",
        "            if len(material_groups) > 0:\n",
        "                axes[1, 0].scatter(material_groups['material_count'],\n",
        "                                 material_groups['centipawn_loss'],\n",
        "                                 alpha=0.6, s=50, label=model_name)\n",
        "\n",
        "        axes[1, 0].set_xlabel('Material Count')\n",
        "        axes[1, 0].set_ylabel('Average CP Loss')\n",
        "        axes[1, 0].set_title('CP Loss vs Material Count', fontweight='bold')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 4. Inference Time vs Response Tokens\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            if len(df) > 500:\n",
        "                df_sample = df.sample(500, random_state=42)\n",
        "            else:\n",
        "                df_sample = df\n",
        "            axes[1, 1].scatter(df_sample['response_tokens'],\n",
        "                             df_sample['inference_time'],\n",
        "                             alpha=0.4, s=30, label=model_name)\n",
        "\n",
        "        axes[1, 1].set_xlabel('Response Tokens')\n",
        "        axes[1, 1].set_ylabel('Inference Time (s)')\n",
        "        axes[1, 1].set_title('Generation Speed: Tokens vs Time', fontweight='bold')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Saved: {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def plot_time_series_trends(self, save_path='time_series_trends.png'):\n",
        "        \"\"\"Plot performance trends across game progression.\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        # 1. Best Move Rate by Move Number (line plot)\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            move_groups = df.groupby('move_number').agg({\n",
        "                'is_best': 'mean',\n",
        "                'fen': 'count'\n",
        "            }).reset_index()\n",
        "            move_groups = move_groups[move_groups['fen'] >= 3]\n",
        "            if len(move_groups) > 0:\n",
        "                move_groups = move_groups.sort_values('move_number')\n",
        "                axes[0, 0].plot(move_groups['move_number'],\n",
        "                              move_groups['is_best'] * 100,\n",
        "                              marker='o', linewidth=2, markersize=6,\n",
        "                              label=model_name, alpha=0.8)\n",
        "\n",
        "        axes[0, 0].set_xlabel('Move Number')\n",
        "        axes[0, 0].set_ylabel('Best Move Rate (%)')\n",
        "        axes[0, 0].set_title('Best Move Rate Across Game', fontweight='bold')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        axes[0, 0].set_ylim([0, 100])\n",
        "\n",
        "        # 2. CP Loss by Move Number\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            legal_df = df[df['is_legal']]\n",
        "            move_groups = legal_df.groupby('move_number').agg({\n",
        "                'centipawn_loss': 'mean',\n",
        "                'fen': 'count'\n",
        "            }).reset_index()\n",
        "            move_groups = move_groups[move_groups['fen'] >= 3]\n",
        "            if len(move_groups) > 0:\n",
        "                move_groups = move_groups.sort_values('move_number')\n",
        "                axes[0, 1].plot(move_groups['move_number'],\n",
        "                              move_groups['centipawn_loss'],\n",
        "                              marker='o', linewidth=2, markersize=6,\n",
        "                              label=model_name, alpha=0.8)\n",
        "\n",
        "        axes[0, 1].set_xlabel('Move Number')\n",
        "        axes[0, 1].set_ylabel('Average CP Loss')\n",
        "        axes[0, 1].set_title('CP Loss Across Game', fontweight='bold')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # 3. Legal Rate by Material Count\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            material_groups = df.groupby('material_count').agg({\n",
        "                'is_legal': 'mean',\n",
        "                'fen': 'count'\n",
        "            }).reset_index()\n",
        "            material_groups = material_groups[material_groups['fen'] >= 3]\n",
        "            if len(material_groups) > 0:\n",
        "                material_groups = material_groups.sort_values('material_count')\n",
        "                axes[1, 0].plot(material_groups['material_count'],\n",
        "                              material_groups['is_legal'] * 100,\n",
        "                              marker='o', linewidth=2, markersize=6,\n",
        "                              label=model_name, alpha=0.8)\n",
        "\n",
        "        axes[1, 0].set_xlabel('Material Count')\n",
        "        axes[1, 0].set_ylabel('Legal Rate (%)')\n",
        "        axes[1, 0].set_title('Legal Rate by Material Count', fontweight='bold')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "        axes[1, 0].set_ylim([0, 100])\n",
        "\n",
        "        # 4. Performance by Position Type (grouped line)\n",
        "        pos_type_order = ['losing', 'equal', 'advantage', 'winning']\n",
        "        x_pos = np.arange(len(pos_type_order))\n",
        "\n",
        "        for model_name in self.model_names:\n",
        "            df = self.dataframes[model_name]\n",
        "            values = []\n",
        "            for pos_type in pos_type_order:\n",
        "                type_df = df[df['position_type'] == pos_type]\n",
        "                if len(type_df) > 0:\n",
        "                    values.append(type_df['is_best'].mean() * 100)\n",
        "                else:\n",
        "                    values.append(None)\n",
        "\n",
        "            # Only plot if we have at least 2 valid points\n",
        "            valid_values = [v for v in values if v is not None]\n",
        "            if len(valid_values) >= 2:\n",
        "                axes[1, 1].plot(x_pos, values, marker='o', linewidth=2,\n",
        "                              markersize=8, label=model_name, alpha=0.8)\n",
        "\n",
        "        axes[1, 1].set_xlabel('Position Type')\n",
        "        axes[1, 1].set_ylabel('Best Move Rate (%)')\n",
        "        axes[1, 1].set_title('Performance by Position Type', fontweight='bold')\n",
        "        axes[1, 1].set_xticks(x_pos)\n",
        "        axes[1, 1].set_xticklabels([p.capitalize() for p in pos_type_order])\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        axes[1, 1].set_ylim([0, 100])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Saved: {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def generate_full_report(self, output_dir='chess_analysis_results'):\n",
        "        \"\"\"Generate all plots and reports.\"\"\"\n",
        "        Path(output_dir).mkdir(exist_ok=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"GENERATING COMPREHENSIVE COMPARATIVE ANALYSIS\")\n",
        "        print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "        # Summary table\n",
        "        summary_df = self.create_summary_table()\n",
        "        summary_df.to_csv(f'{output_dir}/summary_comparison.csv', index=False)\n",
        "\n",
        "        # Generate all plots\n",
        "        print(\"\\nGenerating visualizations...\")\n",
        "        self.plot_core_metrics(f'{output_dir}/01_core_metrics.png')\n",
        "        self.plot_move_quality_breakdown(f'{output_dir}/02_move_quality.png')\n",
        "        self.plot_centipawn_analysis(f'{output_dir}/03_centipawn_analysis.png')\n",
        "        self.plot_phase_analysis(f'{output_dir}/04_phase_analysis.png')\n",
        "        self.plot_position_type_analysis(f'{output_dir}/05_position_type.png')\n",
        "        self.plot_tactical_positional(f'{output_dir}/06_tactical_positional.png')\n",
        "        self.plot_efficiency_metrics(f'{output_dir}/07_efficiency.png')\n",
        "        self.plot_radar_comparison(f'{output_dir}/08_radar_comparison.png')\n",
        "        self.plot_agreement_matrix(f'{output_dir}/09_agreement_matrix.png')\n",
        "        self.plot_elo_estimation(f'{output_dir}/10_elo_estimation.png')\n",
        "        self.plot_scatter_relationships(f'{output_dir}/11_scatter_relationships.png')\n",
        "        self.plot_time_series_trends(f'{output_dir}/12_time_series_trends.png')\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"✓ ANALYSIS COMPLETE!\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"\\nAll results saved to '{output_dir}/' directory\")\n",
        "        print(\"\\nGenerated files:\")\n",
        "        print(\"  📊 summary_comparison.csv - Detailed metrics table\")\n",
        "        print(\"  📈 01_core_metrics.png - Core performance metrics\")\n",
        "        print(\"  📈 02_move_quality.png - Move quality breakdown\")\n",
        "        print(\"  📈 03_centipawn_analysis.png - Centipawn loss analysis\")\n",
        "        print(\"  📈 04_phase_analysis.png - Game phase performance\")\n",
        "        print(\"  📈 05_position_type.png - Position type analysis\")\n",
        "        print(\"  📈 06_tactical_positional.png - Tactical vs positional\")\n",
        "        print(\"  📈 07_efficiency.png - Speed and efficiency metrics\")\n",
        "        print(\"  📈 08_radar_comparison.png - Multi-dimensional radar chart\")\n",
        "        print(\"  📈 09_agreement_matrix.png - Model agreement heatmap\")\n",
        "        print(\"  📈 10_elo_estimation.png - Estimated playing strength\")\n",
        "        print(\"  📈 11_scatter_relationships.png - Scatter plots of relationships\")\n",
        "        print(\"  📈 12_time_series_trends.png - Performance trends across game\")\n",
        "        print(f\"\\n{'='*80}\\n\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load all result CSVs\n",
        "    csv_pattern = \"*_results.csv\"  # This will match all files ending in _results.csv\n",
        "\n",
        "    # Or specify explicitly:\n",
        "    # csv_files = [\"sft_model_results.csv\", \"grpo_model_results.csv\", \"baseline_results.csv\"]\n",
        "\n",
        "    comparison = ChessModelComparison(csv_pattern)\n",
        "    comparison.generate_full_report(output_dir='chess_analysis_results')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "439fc85115e94eb6a17fc7e7a85712f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_662de5dba508463b80f89dcce67d0128",
              "IPY_MODEL_b6974b786f284e65bbe9ac64c08a1b9b",
              "IPY_MODEL_66e773c76d794f479cd180ee51cf6801"
            ],
            "layout": "IPY_MODEL_c45a1a594e534c889ceefb11c12596d6"
          }
        },
        "662de5dba508463b80f89dcce67d0128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60b3757e1aa747e1b80778ce23611dd8",
            "placeholder": "​",
            "style": "IPY_MODEL_afdc1bf24c704ee5b7cf777f3f71a3fa",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b6974b786f284e65bbe9ac64c08a1b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9374e0c7cb844882bd9f3f6e64cf2bdc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c137df3d63cf4141b5dca18dc85993b4",
            "value": 2
          }
        },
        "66e773c76d794f479cd180ee51cf6801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e89199761e7400b9a3a3f6a1f2d736c",
            "placeholder": "​",
            "style": "IPY_MODEL_b12bdd9215c247668e38a2a9c432eb3b",
            "value": " 2/2 [00:31&lt;00:00, 15.33s/it]"
          }
        },
        "c45a1a594e534c889ceefb11c12596d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60b3757e1aa747e1b80778ce23611dd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afdc1bf24c704ee5b7cf777f3f71a3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9374e0c7cb844882bd9f3f6e64cf2bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c137df3d63cf4141b5dca18dc85993b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e89199761e7400b9a3a3f6a1f2d736c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b12bdd9215c247668e38a2a9c432eb3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
